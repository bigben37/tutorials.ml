{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyhqszU3ssxmUaPMRhO6Lv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bigben37/tutorials.ml/blob/main/linear_regression_taxi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emRnapJbzYFg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load required modules"
      ],
      "metadata": {
        "id": "TOCTfbZabhG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install required libraries\n",
        "\n",
        "!pip install google-ml-edu==0.1.3 \\\n",
        "  keras~=3.8.0 \\\n",
        "  matplotlib~=3.10.0 \\\n",
        "  numpy~=2.0.0 \\\n",
        "  pandas~=2.2.0 \\\n",
        "  tensorflow~=2.18.0\n",
        "\n",
        "print('\\n\\nAll requirements successfully installed.')"
      ],
      "metadata": {
        "id": "SRL3_HoUb__L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Code - Load dependencies\n",
        "\n",
        "# data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# machine learning\n",
        "import keras\n",
        "import ml_edu.experiment\n",
        "import ml_edu.results\n",
        "\n",
        "# data visualization\n",
        "import plotly.express as px"
      ],
      "metadata": {
        "id": "feXKx0e_cvIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "chicago_taxi_dataset = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/chicago_taxi_train.csv\")"
      ],
      "metadata": {
        "id": "ku4dhFpWdEoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Code - Read dataset\n",
        "training_df = chicago_taxi_dataset.loc[:,('TRIP_MILES', 'TRIP_SECONDS', 'FARE', 'COMPANY', 'PAYMENT_TYPE', 'TIP_RATE')]\n",
        "print('Read dataset completed successfully.')\n",
        "print('Total number of rows: {0}\\n\\n'.format(len(training_df.index)))\n",
        "training_df.head(200)"
      ],
      "metadata": {
        "id": "J_a4yFdedbTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Exploration"
      ],
      "metadata": {
        "id": "WD45zB5xecXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Code - View dataset statistics\n",
        "\n",
        "print('Total number of rows: {0}\\n\\n'.format(len(training_df.index)))\n",
        "training_df.describe(include='all')"
      ],
      "metadata": {
        "id": "VZJ4eUQAfNmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0wNFBz51hSFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VQ9R5o7CcFzY"
      },
      "cell_type": "code",
      "source": [
        "#@title Double-click or run to view answers about dataset statistics\n",
        "\n",
        "answer = '''\n",
        "What is the maximum fare? \t\t\t\t              Answer: $159.25\n",
        "What is the mean distance across all trips? \t\tAnswer: 8.2895 miles\n",
        "How many cab companies are in the dataset? \t\t  Answer: 31\n",
        "What is the most frequent payment type? \t\t    Answer: Credit Card\n",
        "Are any features missing data? \t\t\t\t          Answer: No\n",
        "'''\n",
        "\n",
        "# You should be able to find the answers to the questions about the dataset\n",
        "# by inspecting the table output after running the DataFrame describe method.\n",
        "#\n",
        "# Run this code cell to verify your answers.\n",
        "\n",
        "# What is the maximum fare?\n",
        "max_fare = training_df['FARE'].max()\n",
        "print(\"What is the maximum fare? \t\t\t\tAnswer: ${fare:.2f}\".format(fare = max_fare))\n",
        "\n",
        "# What is the mean distance across all trips?\n",
        "mean_distance = training_df['TRIP_MILES'].mean()\n",
        "print(\"What is the mean distance across all trips? \t\tAnswer: {mean:.4f} miles\".format(mean = mean_distance))\n",
        "\n",
        "# How many cab companies are in the dataset?\n",
        "num_unique_companies =  training_df['COMPANY'].nunique()\n",
        "print(\"How many cab companies are in the dataset? \t\tAnswer: {number}\".format(number = num_unique_companies))\n",
        "\n",
        "# What is the most frequent payment type?\n",
        "most_freq_payment_type = training_df['PAYMENT_TYPE'].value_counts().idxmax()\n",
        "print(\"What is the most frequent payment type? \t\tAnswer: {type}\".format(type = most_freq_payment_type))\n",
        "\n",
        "# Are any features missing data?\n",
        "missing_values = training_df.isnull().sum().sum()\n",
        "print(\"Are any features missing data? \t\t\t\tAnswer:\", \"No\" if missing_values == 0 else \"Yes\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#@title code - View Correlation Matrix\n",
        "training_df.corr(numeric_only=True)"
      ],
      "metadata": {
        "id": "5vkjuV60ilAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Double-click to view answers about the correlation matrix\n",
        "\n",
        "# Which feature correlates most strongly to the label FARE?\n",
        "# ---------------------------------------------------------\n",
        "answer = '''\n",
        "The feature with the strongest correlation to the FARE is TRIP_MILES.\n",
        "As you might expect, TRIP_MILES looks like a good feature to start with to train\n",
        "the model. Also, notice that the feature TRIP_SECONDS has a strong correlation\n",
        "with fare too.\n",
        "'''\n",
        "print(answer)\n",
        "\n",
        "\n",
        "# Which feature correlates least strongly to the label FARE?\n",
        "# -----------------------------------------------------------\n",
        "answer = '''The feature with the weakest correlation to the FARE is TIP_RATE.'''\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvrbqNJjkOzD",
        "outputId": "6b765e9e-7f95-4853-b104-b1e5c00f35c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The feature with the strongest correlation to the FARE is TRIP_MILES.\n",
            "As you might expect, TRIP_MILES looks like a good feature to start with to train\n",
            "the model. Also, notice that the feature TRIP_SECONDS has a strong correlation\n",
            "with fare too.\n",
            "\n",
            "The feature with the weakest correlation to the FARE is TIP_RATE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Code - View pairplot\n",
        "px.scatter_matrix(training_df, dimensions=[\"FARE\", \"TRIP_MILES\", \"TRIP_SECONDS\"])"
      ],
      "metadata": {
        "id": "wxqPUp38kgsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CV7LVkZDsXnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W6a7dtcCob-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aefee94d-fea0-4699-fe39-15d278eaac35"
      },
      "cell_type": "code",
      "source": [
        "#@title Code - Define ML functions\n",
        "\n",
        "def create_model(\n",
        "    settings: ml_edu.experiment.ExperimentSettings,\n",
        "    metrics: list[keras.metrics.Metric],\n",
        ") -> keras.Model:\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
        "  # Describe the topography of the model.\n",
        "  # The topography of a simple linear regression model\n",
        "  # is a single node in a single layer.\n",
        "  inputs = {name: keras.Input(shape=(1,), name=name) for name in settings.input_features}\n",
        "  concatenated_inputs = keras.layers.Concatenate()(list(inputs.values()))\n",
        "  outputs = keras.layers.Dense(units=1)(concatenated_inputs)\n",
        "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "  # Compile the model topography into code that Keras can efficiently\n",
        "  # execute. Configure training to minimize the model's mean squared error.\n",
        "  model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=settings.learning_rate),\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=metrics)\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    experiment_name: str,\n",
        "    model: keras.Model,\n",
        "    dataset: pd.DataFrame,\n",
        "    label_name: str,\n",
        "    settings: ml_edu.experiment.ExperimentSettings,\n",
        ") -> ml_edu.experiment.Experiment:\n",
        "  \"\"\"Train the model by feeding it data.\"\"\"\n",
        "\n",
        "  # Feed the model the feature and the label.\n",
        "  # The model will train for the specified number of epochs.\n",
        "  features = {name: dataset[name].values for name in settings.input_features}\n",
        "  label = dataset[label_name].values\n",
        "  history = model.fit(x=features,\n",
        "                      y=label,\n",
        "                      batch_size=settings.batch_size,\n",
        "                      epochs=settings.number_epochs)\n",
        "\n",
        "  return ml_edu.experiment.Experiment(\n",
        "      name=experiment_name,\n",
        "      settings=settings,\n",
        "      model=model,\n",
        "      epochs=history.epoch,\n",
        "      metrics_history=pd.DataFrame(history.history),\n",
        "  )\n",
        "\n",
        "print(\"SUCCESS: defining linear regression functions complete.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUCCESS: defining linear regression functions complete.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z1K80k1MtRqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F_17Aum6IG1F"
      },
      "cell_type": "code",
      "source": [
        "#@title Code - Experiment 1\n",
        "\n",
        "# The following variables are the hyperparameters.\n",
        "settings_1 = ml_edu.experiment.ExperimentSettings(\n",
        "    learning_rate = 0.001,\n",
        "    number_epochs = 20,\n",
        "    batch_size = 50,\n",
        "    input_features = ['TRIP_MILES']\n",
        ")\n",
        "\n",
        "metrics = [keras.metrics.RootMeanSquaredError(name='rmse')]\n",
        "\n",
        "model_1 = create_model(settings_1, metrics)\n",
        "\n",
        "experiment_1 = train_model('one_feature', model_1, training_df, 'FARE', settings_1)\n",
        "\n",
        "ml_edu.results.plot_experiment_metrics(experiment_1, ['rmse'])\n",
        "ml_edu.results.plot_model_predictions(experiment_1, training_df, 'FARE')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Double-click to view answers for training model with one feature\n",
        "\n",
        "# How many epochs did it take to converge on the final model?\n",
        "# -----------------------------------------------------------------------------\n",
        "answer = \"\"\"\n",
        "Use the loss curve to see where the loss begins to level off during training.\n",
        "\n",
        "With this set of hyperparameters:\n",
        "\n",
        "  learning_rate = 0.001\n",
        "  epochs = 20\n",
        "  batch_size = 50\n",
        "\n",
        "it takes about 5 epochs for the training run to converge to the final model.\n",
        "\"\"\"\n",
        "print(answer)\n",
        "\n",
        "# How well does the model fit the sample data?\n",
        "# -----------------------------------------------------------------------------\n",
        "answer = '''\n",
        "It appears from the model plot that the model fits the sample data fairly well.\n",
        "'''\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "nocl40UItoze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Code - Experiment 2\n",
        "\n",
        "# The following variables are the hyperparameters.\n",
        "# TODO - Adjust these hyperparameters to see how they impact a training run.\n",
        "settings_2 = ml_edu.experiment.ExperimentSettings(\n",
        "    learning_rate = 0.001,\n",
        "    number_epochs = 20,\n",
        "    batch_size = 500,\n",
        "    input_features = ['TRIP_MILES']\n",
        ")\n",
        "\n",
        "metrics = [keras.metrics.RootMeanSquaredError(name='rmse')]\n",
        "\n",
        "model_2 = create_model(settings_2, metrics)\n",
        "\n",
        "experiment_2 = train_model('one_feature_hyper', model_2, training_df, 'FARE', settings_2)\n",
        "\n",
        "ml_edu.results.plot_experiment_metrics(experiment_2, ['rmse'])\n",
        "ml_edu.results.plot_model_predictions(experiment_2, training_df, 'FARE')"
      ],
      "metadata": {
        "id": "WVSE0V2ot3m1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Double-click to view answers for hyperparameter experiments\n",
        "\n",
        "# How did raising the learning rate impact your ability to train the model?\n",
        "# -----------------------------------------------------------------------------\n",
        "answer = \"\"\"\n",
        "When the learning rate is too high, the loss curve bounces around and does not\n",
        "appear to be moving towards convergence with each iteration. Also, notice that\n",
        "the predicted model does not fit the data very well. With a learning rate that\n",
        "is too high, it is unlikely that you will be able to train a model with good\n",
        "results.\n",
        "\"\"\"\n",
        "print(answer)\n",
        "\n",
        "# How did lowering the learning rate impact your ability to train the model?\n",
        "# -----------------------------------------------------------------------------\n",
        "answer = '''\n",
        "When the learning rate is too small, it may take longer for the loss curve to\n",
        "converge. With a small learning rate the loss curve decreases slowly, but does\n",
        "not show a dramatic drop or leveling off. With a small learning rate you could\n",
        "increase the number of epochs so that your model will eventually converge, but\n",
        "it will take longer.\n",
        "'''\n",
        "print(answer)\n",
        "\n",
        "# Did changing the batch size effect your training results?\n",
        "# -----------------------------------------------------------------------------\n",
        "answer = '''\n",
        "Increasing the batch size makes each epoch run faster, but as with the smaller\n",
        "learning rate, the model does not converge with just 20 epochs. If you have\n",
        "time, try increasing the number of epochs and eventually you should see the\n",
        "model converge.\n",
        "'''\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "9KFprn6SviJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Code - Experiment 3\n",
        "\n",
        "# The following variables are the hyperparameters.\n",
        "settings_3 = ml_edu.experiment.ExperimentSettings(\n",
        "    learning_rate = 0.001,\n",
        "    number_epochs = 20,\n",
        "    batch_size = 50,\n",
        "    input_features = ['TRIP_MILES', 'TRIP_MINUTES']\n",
        ")\n",
        "\n",
        "training_df['TRIP_MINUTES'] = training_df['TRIP_SECONDS']/60\n",
        "\n",
        "metrics = [keras.metrics.RootMeanSquaredError(name='rmse')]\n",
        "\n",
        "model_3 = create_model(settings_3, metrics)\n",
        "\n",
        "experiment_3 = train_model('two_features', model_3, training_df, 'FARE', settings_3)\n",
        "\n",
        "ml_edu.results.plot_experiment_metrics(experiment_3, ['rmse'])\n",
        "ml_edu.results.plot_model_predictions(experiment_3, training_df, 'FARE')"
      ],
      "metadata": {
        "id": "auwNKjcqvsVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gvXk7jCZwcC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uFkKK5t33xSX"
      },
      "cell_type": "code",
      "source": [
        "#@title Double-click to view answers for training with two features\n",
        "\n",
        "# Does the model with two features produce better results than one using a\n",
        "# single feature?\n",
        "# -----------------------------------------------------------------------------\n",
        "answer = '''\n",
        "To answer this question for your specific training runs, compare the RMSE for\n",
        "each model. For example, if the RMSE for the model trained with one feature was\n",
        "3.7457 and the RMSE for the model with two features is 3.4787, that means that\n",
        "on average the model with two features makes predictions that are about $0.27\n",
        "closer to the observed fare.\n",
        "\n",
        "'''\n",
        "print(answer)\n",
        "\n",
        "# Does it make a difference if you use TRIP_SECONDS instead of TRIP_MINUTES?\n",
        "# -----------------------------------------------------------------------------\n",
        "answer = '''\n",
        "When training a model with more than one feature, it is important that all\n",
        "numeric values are roughly on the same scale. In this case, TRIP_SECONDS and\n",
        "TRIP_MILES do not meet this criteria. The mean value for TRIP_MILES is 8.3 and\n",
        "the mean for TRIP_SECONDS is 1,320; that is two orders of magnitude difference.\n",
        "In contrast, the mean for TRIP_MINUTES is 22, which is more similar to the scale\n",
        "of TRIP_MILES (8.3) than TRIP_SECONDS (1,320). Of course, this is not the\n",
        "only way to scale values before training, but you will learn about that in\n",
        "another module.\n",
        "'''\n",
        "print(answer)\n",
        "\n",
        "# How well do you think the model comes to the ground truth fare calculation for\n",
        "# Chicago taxi trips?\n",
        "# -----------------------------------------------------------------------------\n",
        "answer = '''\n",
        "In reality, Chicago taxi cabs use a documented formula to determine cab fares.\n",
        "For a single passenger paying cash, the fare is calculated like this:\n",
        "\n",
        "FARE = 2.25 * TRIP_MILES + 0.12 * TRIP_MINUTES + 3.25\n",
        "\n",
        "Typically with machine learning problems you would not know the 'correct'\n",
        "formula, but in this case you can use this knowledge to evaluate your model.\n",
        "Take a look at your model output (the weights and bias) and determine how\n",
        "well it matches the ground truth fare calculation. You should find that the\n",
        "model is roughly close to this formula.\n",
        "'''\n",
        "print(answer)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ml_edu.results.compare_experiment([experiment_1, experiment_3], ['rmse'], training_df, training_df['FARE'].values)"
      ],
      "metadata": {
        "id": "Z0oaxXMMwlMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Code - Define functions to make predictions\n",
        "def format_currency(x):\n",
        "  return \"${:.2f}\".format(x)\n",
        "\n",
        "def build_batch(df, batch_size):\n",
        "  batch = df.sample(n=batch_size).copy()\n",
        "  batch.set_index(np.arange(batch_size), inplace=True)\n",
        "  return batch\n",
        "\n",
        "def predict_fare(model, df, features, label, batch_size=50):\n",
        "  batch = build_batch(df, batch_size)\n",
        "  predicted_values = model.predict_on_batch(x={name: batch[name].values for name in features})\n",
        "\n",
        "  data = {\"PREDICTED_FARE\": [], \"OBSERVED_FARE\": [], \"L1_LOSS\": [],\n",
        "          features[0]: [], features[1]: []}\n",
        "  for i in range(batch_size):\n",
        "    predicted = predicted_values[i][0]\n",
        "    observed = batch.at[i, label]\n",
        "    data[\"PREDICTED_FARE\"].append(format_currency(predicted))\n",
        "    data[\"OBSERVED_FARE\"].append(format_currency(observed))\n",
        "    data[\"L1_LOSS\"].append(format_currency(abs(observed - predicted)))\n",
        "    data[features[0]].append(batch.at[i, features[0]])\n",
        "    data[features[1]].append(\"{:.2f}\".format(batch.at[i, features[1]]))\n",
        "\n",
        "  output_df = pd.DataFrame(data)\n",
        "  return output_df\n",
        "\n",
        "def show_predictions(output):\n",
        "  header = \"-\" * 80\n",
        "  banner = header + \"\\n\" + \"|\" + \"PREDICTIONS\".center(78) + \"|\" + \"\\n\" + header\n",
        "  print(banner)\n",
        "  print(output)\n",
        "  return"
      ],
      "metadata": {
        "id": "31hYCa3OxF7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Code - Make predictions\n",
        "\n",
        "output = predict_fare(experiment_3.model, training_df, experiment_3.settings.input_features, 'FARE')\n",
        "show_predictions(output)"
      ],
      "metadata": {
        "id": "fBXbDwlPxPZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Double-click to view answers for validate model\n",
        "\n",
        "# How close is the predicted value to the label value?\n",
        "# -----------------------------------------------------------------------------\n",
        "answer = '''\n",
        "Based on a random sampling of examples, the model seems to do pretty well\n",
        "predicting the fare for a taxi ride. Most of the predicted values do not vary\n",
        "significantly from the observed value. You should be able to see this by looking\n",
        "at the column L1_LOSS = |observed - predicted|.\n",
        "'''\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "hfGGsyIDxib4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}